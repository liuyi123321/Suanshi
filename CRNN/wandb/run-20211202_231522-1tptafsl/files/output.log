
load weights/last_40_2.387116779112562_0.6742770167427702.pt model success!
[1mparameter[22m: epochs=60,batch_size=256,lr=0.001,device=cuda,chinese=C:/Users/Bowell/Desktop/DEEPLEARNING/data2(1)/Desktop/crnn-master/data/chinese.txt,images=C:/Users/Bowell/Desktop/DEEPLEARNING/data2(1)/Desktop/crnn-master/data/images/,labelsC:/Users/Bowell/Desktop/DEEPLEARNING/data2(1)/Desktop/crnn-master/data/labels/,imgH=32,nc=1,nh=256,val_epoch=5,save_all=False,best=0.5,test=False,all=False,weights=weights/last_40_2.387116779112562_0.6742770167427702.pt,name=weights
[1moptimizer[22m:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
[1mmodel[22m:
CRNN(
  (cnn): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU(inplace=True)
    (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)
    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)
    (22): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): ReLU(inplace=True)
  )
  (rnn): Sequential(
    (0): BidirectionalLSTM(
      (rnn): LSTM(512, 256, bidirectional=True)
      (embedding): Linear(in_features=512, out_features=256, bias=True)
    )
    (1): BidirectionalLSTM(
      (rnn): LSTM(256, 256, bidirectional=True)
      (embedding): Linear(in_features=512, out_features=19, bias=True)
    )
  )
)








epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.91s/it, acc=0.805, loss=0.743]
epoch 1: train_loss=1.9649085038278435, train_acc=0.6784409257003654







epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.62s/it, acc=0.95, loss=0.339]
epoch 2: train_loss=0.6361271033091512, train_acc=0.877791311408851







epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/it, acc=0.981, loss=0.182]
epoch 3: train_loss=0.3514122771287516, train_acc=0.9390986601705238







epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.68s/it, acc=0.975, loss=0.0961]
epoch 4: train_loss=0.21059206235810504, train_acc=0.9683313032886723







epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.61s/it, acc=0.975, loss=0.158]
epoch 5: train_loss=0.14741543139861552, train_acc=0.9796995533901746

epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.20s/it, acc=0.772, loss=1.57]
epoch 5: val_loss=2.23798650221919, val_acc=0.6727549467275494









epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.89s/it, acc=0.994, loss=0.0699]
epoch 6: train_loss=0.1123357649697456, train_acc=0.9870077141697118









epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  2.00s/it, acc=1, loss=0.0298]
epoch 7: train_loss=0.09179174227294426, train_acc=0.9898497766950873







epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.70s/it, acc=0.981, loss=0.0907]
epoch 8: train_loss=0.07831365250011696, train_acc=0.9922858302882663








epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.74s/it, acc=0.994, loss=0.0667]
epoch 9: train_loss=0.06907937703847014, train_acc=0.9935038570848559







epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/it, acc=0.994, loss=0.0409]
epoch 10: train_loss=0.062386527082758415, train_acc=0.9939098660170523

epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.38s/it, acc=0.834, loss=1.08]
epoch 10: val_loss=2.3360772212709286, val_acc=0.69558599695586








epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.71s/it, acc=0.994, loss=0.041]
epoch 11: train_loss=0.05569753654594592, train_acc=0.9939098660170523







epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/it, acc=0.994, loss=0.0339]
epoch 12: train_loss=0.050657201674814106, train_acc=0.9947218838814454







epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/it, acc=0.994, loss=0.0889]
epoch 13: train_loss=0.046151221113092666, train_acc=0.9947218838814454








epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.68s/it, acc=0.994, loss=0.0281]
epoch 14: train_loss=0.041655467188653546, train_acc=0.9947218838814454







epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.71s/it, acc=1, loss=0.0145]
epoch 15: train_loss=0.03977664650527143, train_acc=0.9951278928136419

epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.27s/it, acc=0.828, loss=1.17]
epoch 15: val_loss=2.5458635768571036, val_acc=0.684931506849315








epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.85s/it, acc=0.994, loss=0.0682]
epoch 16: train_loss=0.036303797825245274, train_acc=0.9959399106780349








epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.72s/it, acc=0.987, loss=0.0652]
epoch 17: train_loss=0.03339767688374862, train_acc=0.9967519285424279







epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.64s/it, acc=1, loss=0.0101]
epoch 18: train_loss=0.03155006604421153, train_acc=0.9971579374746244







epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/it, acc=1, loss=0.0126]
epoch 19: train_loss=0.030009423529671016, train_acc=0.9971579374746244








epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.62s/it, acc=1, loss=0.0106]
epoch 20: train_loss=0.028154060940310765, train_acc=0.9971579374746244
epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.21s/it, acc=0.862, loss=1.16]
epoch 20: val_loss=2.5520581807175726, val_acc=0.7077625570776256








epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.63s/it, acc=1, loss=0.00838]
epoch 21: train_loss=0.025800139062829585, train_acc=0.997563946406821
epoch 22:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:03<00:07,  1.07s/it, acc=0.992, loss=0.0671]
epoch 22:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:05<00:04,  1.04it/s, acc=0.988, loss=0.0871]
epoch 22:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:06<00:04,  1.16s/it, acc=1, loss=0.0085]
epoch 22:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:08<00:02,  1.03s/it, acc=1, loss=0.00842]
epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.30s/it, acc=1, loss=0.00986]
epoch 22: : 12it [00:13,  1.10s/it, acc=0.996, loss=0.0226]
epoch 22: : 13it [00:15,  1.24s/it, acc=1, loss=0.00918]
  0%|          | 0/10 [00:00<?, ?it/s]6<00:00,  1.63s/it, acc=1, loss=0.0083]
epoch 23:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:03<00:07,  1.07s/it, acc=1, loss=0.00866]
epoch 23:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:05<00:04,  1.06it/s, acc=1, loss=0.00699]
epoch 23:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:06<00:04,  1.14s/it, acc=1, loss=0.00816]
epoch 23:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:08<00:02,  1.02s/it, acc=0.988, loss=0.0717]
epoch 23:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:10<00:01,  1.19s/it, acc=0.996, loss=0.0345]
epoch 23: : 12it [00:13,  1.12s/it, acc=1, loss=0.00821]
epoch 23: : 13it [00:15,  1.25s/it, acc=1, loss=0.00735]
  0%|          | 0/10 [00:00<?, ?it/s]6<00:00,  1.63s/it, acc=1, loss=0.00701]
epoch 24:  10%|â–ˆ         | 1/10 [00:01<00:15,  1.72s/it, acc=0.996, loss=0.0205]
epoch 24:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:05<00:04,  1.03it/s, acc=0.996, loss=0.0352]
epoch 24:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:06<00:04,  1.18s/it, acc=0.992, loss=0.0602]
epoch 24:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:08<00:02,  1.04s/it, acc=1, loss=0.00705]
epoch 24:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:10<00:01,  1.18s/it, acc=0.996, loss=0.0273]
epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.32s/it, acc=1, loss=0.00695]
epoch 24: : 12it [00:13,  1.13s/it, acc=0.996, loss=0.0332]
  0%|          | 0/10 [00:00<?, ?it/s]6<00:00,  1.66s/it, acc=1, loss=0.00865]
epoch 25:  10%|â–ˆ         | 1/10 [00:01<00:16,  1.88s/it, acc=1, loss=0.0072]5]
epoch 25:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:03<00:08,  1.16s/it, acc=1, loss=0.00758]]
epoch 25:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:05<00:05,  1.01s/it, acc=0.996, loss=0.0365]
epoch 25:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:07<00:04,  1.20s/it, acc=0.996, loss=0.0305]
epoch 25:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:10<00:01,  1.22s/it, acc=0.992, loss=0.0396]
epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.34s/it, acc=0.996, loss=0.0251]
epoch 25: : 12it [00:14,  1.13s/it, acc=1, loss=0.00706]
  0%|          | 0/3 [00:00<?, ?it/s]16<00:00,  1.68s/it, acc=1, loss=0.00628]
epoch 25:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:02,  1.40s/it, acc=0.625, loss=3.64]]
  0%|          | 0/10 [00:00<?, ?it/s]00:00,  1.17s/it, acc=0.848, loss=1.2] ]
epoch 26:  10%|â–ˆ         | 1/10 [00:01<00:15,  1.68s/it, acc=1, loss=0.00691]]
epoch 26:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:03<00:07,  1.09s/it, acc=0.992, loss=0.0371]
epoch 26:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:05<00:04,  1.03it/s, acc=1, loss=0.00653]
epoch 26:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:06<00:04,  1.18s/it, acc=0.996, loss=0.0227]
epoch 26:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:10<00:01,  1.20s/it, acc=1, loss=0.00662]
epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.32s/it, acc=0.996, loss=0.0306]
epoch 26: : 12it [00:13,  1.13s/it, acc=1, loss=0.0061]
  0%|          | 0/10 [00:00<?, ?it/s]6<00:00,  1.65s/it, acc=1, loss=0.0108]
epoch 27:  10%|â–ˆ         | 1/10 [00:01<00:15,  1.71s/it, acc=1, loss=0.00723]
epoch 27:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:03<00:07,  1.09s/it, acc=1, loss=0.0078]
epoch 27:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:05<00:04,  1.03it/s, acc=1, loss=0.00627]
epoch 27:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:06<00:04,  1.15s/it, acc=0.996, loss=0.0288]
epoch 27:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:08<00:02,  1.03s/it, acc=0.992, loss=0.0508]
epoch 27:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:10<00:01,  1.21s/it, acc=1, loss=0.00605]
epoch 27: : 12it [00:13,  1.13s/it, acc=1, loss=0.00609]
epoch 27: : 13it [00:15,  1.27s/it, acc=0.992, loss=0.0296]
  0%|          | 0/10 [00:00<?, ?it/s]6<00:00,  1.67s/it, acc=1, loss=0.00664]
epoch 28:  10%|â–ˆ         | 1/10 [00:02<00:20,  2.24s/it, acc=1, loss=0.00683]]
epoch 28:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:04<00:09,  1.31s/it, acc=0.992, loss=0.0522]
epoch 28:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:05<00:05,  1.09s/it, acc=1, loss=0.00616]
epoch 28:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:09<00:02,  1.07s/it, acc=1, loss=0.00584]
epoch 28:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:11<00:01,  1.22s/it, acc=0.996, loss=0.0228]
epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.35s/it, acc=0.996, loss=0.0117]
epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.35s/it, acc=0.996, loss=0.0117]
epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.35s/it, acc=0.996, loss=0.0117]
epoch 28: train_loss=0.017427301798900646, train_acc=0.997563946406821oss=0.0117]
epoch 28: train_loss=0.017427301798900646, train_acc=0.997563946406821oss=0.0117]
epoch 28: train_loss=0.017427301798900646, train_acc=0.997563946406821oss=0.0117]
epoch 28: train_loss=0.017427301798900646, train_acc=0.997563946406821oss=0.0117]
epoch 28: train_loss=0.017427301798900646, train_acc=0.997563946406821oss=0.0117]
epoch 28: train_loss=0.017427301798900646, train_acc=0.997563946406821oss=0.0117]
epoch 28: train_loss=0.017427301798900646, train_acc=0.997563946406821oss=0.0117]
epoch 28: train_loss=0.017427301798900646, train_acc=0.997563946406821oss=0.0117]
epoch 29: train_loss=0.015962576604789707, train_acc=0.9979699553390174ss=0.0117]
epoch 29: train_loss=0.015962576604789707, train_acc=0.9979699553390174ss=0.0117]
epoch 29: train_loss=0.015962576604789707, train_acc=0.9979699553390174ss=0.0117]
epoch 29: train_loss=0.015962576604789707, train_acc=0.9979699553390174ss=0.0117]
epoch 29: train_loss=0.015962576604789707, train_acc=0.9979699553390174ss=0.0117]
epoch 29: train_loss=0.015962576604789707, train_acc=0.9979699553390174ss=0.0117]
epoch 29: train_loss=0.015962576604789707, train_acc=0.9979699553390174ss=0.0117]
epoch 29: train_loss=0.015962576604789707, train_acc=0.9979699553390174ss=0.0117]
epoch 30: train_loss=0.014703306443217901, train_acc=0.9979699553390174ss=0.0117]
epoch 30: train_loss=0.014703306443217901, train_acc=0.9979699553390174ss=0.0117]
epoch 30: val_loss=2.6400129762414384, val_acc=0.7077625570776256390174ss=0.0117]
epoch 30: val_loss=2.6400129762414384, val_acc=0.7077625570776256390174ss=0.0117]
epoch 30: val_loss=2.6400129762414384, val_acc=0.7077625570776256390174ss=0.0117]
epoch 30: val_loss=2.6400129762414384, val_acc=0.7077625570776256390174ss=0.0117]
epoch 30: val_loss=2.6400129762414384, val_acc=0.7077625570776256390174ss=0.0117]
epoch 30: val_loss=2.6400129762414384, val_acc=0.7077625570776256390174ss=0.0117]
epoch 30: val_loss=2.6400129762414384, val_acc=0.7077625570776256390174ss=0.0117]
epoch 30: val_loss=2.6400129762414384, val_acc=0.7077625570776256390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 31: train_loss=0.013660424543598344, train_acc=0.9979699553390174ss=0.0117]
epoch 32: train_loss=0.012744932217274648, train_acc=0.9979699553390174ss=0.0117]
epoch 32: train_loss=0.012744932217274648, train_acc=0.9979699553390174ss=0.0117]
epoch 32: train_loss=0.012744932217274648, train_acc=0.9979699553390174ss=0.0117]
epoch 32: train_loss=0.012744932217274648, train_acc=0.9979699553390174ss=0.0117]
epoch 32: train_loss=0.012744932217274648, train_acc=0.9979699553390174ss=0.0117]
epoch 32: train_loss=0.012744932217274648, train_acc=0.9979699553390174ss=0.0117]
epoch 32: train_loss=0.012744932217274648, train_acc=0.9979699553390174ss=0.0117]
epoch 32: train_loss=0.012744932217274648, train_acc=0.9979699553390174ss=0.0117]
epoch 33: train_loss=0.012322096722037918, train_acc=0.9979699553390174ss=0.0117]
epoch 33: train_loss=0.012322096722037918, train_acc=0.9979699553390174ss=0.0117]
epoch 33: train_loss=0.012322096722037918, train_acc=0.9979699553390174ss=0.0117]
epoch 33: train_loss=0.012322096722037918, train_acc=0.9979699553390174ss=0.0117]
epoch 33: train_loss=0.012322096722037918, train_acc=0.9979699553390174ss=0.0117]
epoch 33: train_loss=0.012322096722037918, train_acc=0.9979699553390174ss=0.0117]
epoch 33: train_loss=0.012322096722037918, train_acc=0.9979699553390174ss=0.0117]
epoch 33: train_loss=0.012322096722037918, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 34: train_loss=0.011120012461824529, train_acc=0.9979699553390174ss=0.0117]
epoch 35: train_loss=0.010203850787198016, train_acc=0.9983759642712144ss=0.0117]
epoch 35: val_loss=2.6808774068475314, val_acc=0.7077625570776256712144ss=0.0117]
epoch 35: val_loss=2.6808774068475314, val_acc=0.7077625570776256712144ss=0.0117]
epoch 35: val_loss=2.6808774068475314, val_acc=0.7077625570776256712144ss=0.0117]
epoch 35: val_loss=2.6808774068475314, val_acc=0.7077625570776256712144ss=0.0117]
epoch 35: val_loss=2.6808774068475314, val_acc=0.7077625570776256712144ss=0.0117]
epoch 35: val_loss=2.6808774068475314, val_acc=0.7077625570776256712144ss=0.0117]
